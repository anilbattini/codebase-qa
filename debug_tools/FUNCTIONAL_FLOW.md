# FUNCTIONAL_FLOW DIAGRAM - UPDATED for 2025-09-03 ENHANCEMENTS

---

## ðŸŸ¦ RAG Index Build & Ready Flow

**Provider Selection & Configuration:**  
User opens application and configures provider settings  
â†“  
[UIComponents.render_sidebar_config â€“ Provider Selection, Line 72, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L72)  
	â””â”€ **NEW**: Renders provider selection: "Choose Provider...", "Ollama (Local)", "Cloud (OpenAI Compatible)"  
	â””â”€ **NEW**: For Ollama: Shows locked model and endpoint fields for consistency  
	â””â”€ **NEW**: For Cloud: Shows endpoint selection (Environment/Custom) and API key validation  
	â””â”€ **NEW**: Validates provider settings and shows connection status  
	â””â”€ **NEW**: Displays embedding model configuration (always local Ollama for embeddings)  
â†“  
[ModelConfig.set_provider, Line 214, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L214)  
	â””â”€ **NEW**: Sets active provider (ollama or cloud) in centralized configuration  
	â””â”€ **NEW**: Validates provider choice and updates all related settings  
â†“  
[ModelConfig.get_llm, Line 70, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L70)  
	â””â”€ **NEW**: Factory method returns appropriate LLM instance (ChatOllama or CustomLLMClient for cloud)  
	â””â”€ **NEW**: Handles provider-specific parameter mapping and configuration  
	â””â”€ **NEW**: Includes fallback logic and error handling for provider switching  
	â””â”€ **NEW**: Ensures consistent parameter handling across different providers  

---

**Project Configuration:**  
Sidebar: user selects project directory, project type, model, and endpoint  
â†“  
[UIComponents.render_sidebar_config, Line 72, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L72)  
	â””â”€ Renders sidebar inputs for project directory, project type, provider configuration  
	â””â”€ Handles user changes, validations, and warnings about existing data  
	â””â”€ **NEW**: Includes provider selection and configuration validation  
	â””â”€ **NEW**: Shows "Disable RAG (query LLM directly)" toggle for LLM-only mode  
â†“  
[RagManager.initialize_session_state, Line 23, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L23)  
	â””â”€ Initializes critical Streamlit session state keys like retriever and QA chain for stable app state  
	â””â”€ Ensures consistent session during build or load operations  
	â””â”€ **NEW**: Initializes provider-specific session state variables  
â†“  
[ProjectConfig.__init__, Line 262, core/config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/config.py#L262)  
	â””â”€ Detects or applies project type (auto/manual detection)  
	â””â”€ Loads language specific file extensions, chunking rules, ignore patterns, and project indicators  
	â””â”€ **NEW**: Supports project type-specific database directories (codebase-qa_<project_type>/)  
	â””â”€ **NEW**: Handles project type switching with database backup and restore  
â†“  
[RagManager.should_rebuild_index, Line 174, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L174)  
	â””â”€ **NEW**: Returns detailed rebuild information: {"rebuild": bool, "reason": str, "files": list}  
	â””â”€ Checks presence of vector DB SQLite file, git/hash tracking files  
	â””â”€ **ENHANCED**: Detects if source files have changed via Git commit differences or working directory changes  
	â””â”€ **NEW**: Distinguishes between incremental rebuild (changed files) and full rebuild (no DB, no tracking)  

---

**REBUILD DECISION LOGIC:**  
- **No Database**: `{"rebuild": True, "reason": "no_database", "files": None}` â†’ Full rebuild  
- **No Tracking**: `{"rebuild": True, "reason": "no_tracking", "files": None}` â†’ Full rebuild  
- **Files Changed**: `{"rebuild": True, "reason": "files_changed", "files": [file_list]}` â†’ Incremental rebuild  
- **No Changes**: `{"rebuild": False, "reason": "no_changes", "files": []}` â†’ Load existing  

---

**PROCESS MANAGEMENT & UI PROTECTION (NEW SECTION):**  
If rebuild is required, protect the build process from UI interference  
â†“  
[ProcessManager.start_rag_build, Line 18, core/process_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/process_manager.py#L18)  
	â””â”€ **NEW**: Marks RAG building as started with timestamp for timeout detection  
	â””â”€ **NEW**: Sets building flag in session state to prevent concurrent operations  
	â””â”€ **NEW**: Disables UI elements that could interfere with build process  
	â””â”€ **NEW**: Provides build timeout detection (10 minutes) and recovery mechanisms  
â†“  
[ProcessManager.disable_ui_during_build, Line 70, core/process_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/process_manager.py#L70)  
	â””â”€ **NEW**: Returns safe UI state during build to prevent user interference  
	â””â”€ **NEW**: Blocks force rebuild, debug mode, and project type changes during build  
	â””â”€ **NEW**: Shows build status with progress and timeout warnings  

---

**FORCE REBUILD HANDLING:**  
If user requests force rebuild (via "ðŸ”„ Force Rebuild" button)  
â†“  
[App.py force rebuild logic, Line 54, core/app.py](https://github.com/anilbattini/codebase-qa/blob/main/core/app.py#L54)  
	â””â”€ **NEW**: Clears existing data and performs complete rebuild regardless of file changes  
	â””â”€ **NEW**: Shows user confirmation: "ðŸ”„ Force Rebuild: User requested complete rebuild. Cleaning existing data..."  
	â””â”€ **NEW**: Uses ProcessManager to protect the force rebuild process  

---

**INCREMENTAL REBUILD (Changed Files Detected):**  
â†“  
[RagManager.build_rag_index with incremental=True, Line 206, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L206)  
	â””â”€ **NEW**: Calls build_rag with incremental=True and files_to_process parameter  
	â””â”€ **NEW**: Shows progress: "ðŸ”„ Incremental Build: Processing X changed files..."  
	â””â”€ **NEW**: Preserves existing database and only processes changed files  

---

**FULL REBUILD (No DB, No Tracking, or Force Rebuild):**  
â†“  
[RagManager.cleanup_existing_files, Line 91, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L91)  
	â””â”€ Deletes existing vector DB directories and clears session state to ensure clean rebuild  
	â””â”€ Handles retry logic with timeout to overcome file locks during cleanup  
	â””â”€ **NEW**: Includes Chroma connection cleanup to prevent database locking issues  
â†“  
[RagManager.build_rag_index with incremental=False, Line 206, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L206)  
	â””â”€ **NEW**: Calls build_rag with incremental=False for full rebuild  
	â””â”€ **NEW**: Shows progress: "ðŸ”„ Full Build: Rebuilding entire RAG index..."  

---

**BUILD PROCESS (build_rag function):**  
â†“  
[build_rag, Line 64, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py#L64)  
	â””â”€ **NEW**: Supports incremental=True/False and files_to_process parameters  
		â””â”€ **NEW**: For incremental builds: preserves existing database, processes only changed files  
		â””â”€ **NEW**: For full builds: cleans database directory, processes all files  
	â””â”€ **ENHANCED**: Shows build mode: "ðŸ”„ Incremental build mode - processing only changed files" or "Full build mode"  
	â””â”€ Reads files, applies chunking per language, extracts semantic metadata  
	â””â”€ Creates output folders and handles incremental file processing via git/hash tracking  
	â””â”€ **NEW**: Uses ModelConfig.get_embedding_model() for consistent embedding model selection  
	â””â”€ Initializes embedding model and verifies Ollama endpoint responsiveness  
	â””â”€ Processes each source file: chunks files, extracts metadata, deduplicates using chunk fingerprints  
	â””â”€ **NEW**: Builds cross-references for enhanced context capabilities  
	â””â”€ Builds code relationships and hierarchical index files  
	â””â”€ Sanitizes chunks and sends batches for embedding via Ollama API  
	â””â”€ **ENHANCED**: Persists embeddings in Chroma vector database with incremental update support  
	â””â”€ Updates file tracking and logs detailed stats on the process  
â†“  
[ProjectConfig.create_directories, Line 342, core/config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/config.py#L342)  
	â””â”€ Ensures all database and logs directories exist for current project type  
	â””â”€ **NEW**: Creates project-type-specific directories (codebase-qa_<project_type>/)  
â†“  
[FileHashTracker.get_changed_files, Line 22, core/git_hash_tracker.py](https://github.com/anilbattini/codebase-qa/blob/main/core/git_hash_tracker.py#L22)  
	â””â”€ **ENHANCED**: Now properly detects Git commit differences using `git diff --name-only {last_commit}..{current_commit}`  
	â””â”€ **NEW**: Combines commit differences + working directory changes for comprehensive change detection  
	â””â”€ **NEW**: Provides detailed logging: "Git commit diff detected X changed files between {last_commit} and {current_commit}"  
	â””â”€ **NEW**: Falls back to content-hash tracking if Git tracking fails  
	â””â”€ **NEW**: Handles gitignore patterns and hierarchical ignore rules  

---

**Cross-Reference Building (NEW STEP):**  
â†“  
[CrossReferenceBuilder.build_cross_references, Line 54, core/cross_reference_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/cross_reference_builder.py#L54)  
	â””â”€ **NEW**: Extracts symbol definitions from method signatures and metadata  
	â””â”€ **NEW**: Builds comprehensive usage maps and call relationships  
	â””â”€ **NEW**: Builds inheritance and interface implementation relationships  
	â””â”€ **NEW**: Detects design pattern instances (Factory, Singleton, Observer, Strategy, etc.)  
	â””â”€ **NEW**: Generates statistics about cross-references and code complexity  
â†“  
[CrossReferenceBuilder.save_cross_references, Line 382, core/cross_reference_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/cross_reference_builder.py#L382)  
	â””â”€ **NEW**: Saves cross-reference data to structured files:  
		â””â”€ cross_references.json (main cross-reference data)  
		â””â”€ call_graph_index.json (function call relationships)  
		â””â”€ inheritance_index.json (class hierarchy mappings)  
		â””â”€ symbol_usage_index.json (symbol usage patterns)  
	â””â”€ **NEW**: Creates quick-lookup files for common queries  

---

**Enhanced Context Building (Phase 3 - NEW STEP):**  
â†“  
[ContextBuilder.load_context_data, Line 34, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L34)  
	â””â”€ **NEW**: Loads cross-reference and hierarchical data for context assembly  
	â””â”€ **NEW**: Initializes multi-strategy context building capabilities  
	â””â”€ **NEW**: Prepares enhanced context layers for query processing  
â†“  
[ModelConfig.get_embedding_model, Line 186, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L186)  
	â””â”€ Retrieves the embedding model name to ensure consistency in embedding dimensions  
	â””â”€ **NEW**: Centralized embedding model configuration prevents dimension mismatches  
â†“  
[ModelConfig.get_ollama_endpoint, Line 202, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L202)  
	â””â”€ Retrieves the Ollama server endpoint URL used for embedding and LLM calls  
	â””â”€ **NEW**: Supports both local Ollama and cloud provider endpoints  
â†“  
[chunker_factory.get_chunker, Line 164, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py#L164)  
	â””â”€ Selects language-specific chunking strategy function per file extension  
	â””â”€ **NEW**: Enhanced semantic chunking with context hierarchy and improved overlap  
â†“  
[SemanticChunker.create_semantic_chunker, Line 16, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py#L16)  
	â””â”€ Executes semantic chunking, splitting code into meaningful segments for embedding  
	â””â”€ **NEW**: Config-driven, semantic-aware chunking with context hierarchy  
	â””â”€ **NEW**: Calculates semantic richness scores and detects chunk types  
â†“  
[MetadataExtractor.create_enhanced_metadata, Line 21, core/metadata_extractor.py](https://github.com/anilbattini/codebase-qa/blob/main/core/metadata_extractor.py#L21)  
	â””â”€ Extracts detailed chunk meta class names, function names, dependencies, semantic anchors  
	â””â”€ **NEW**: Enhanced method signature extraction for multiple languages  
	â””â”€ **NEW**: Design pattern detection and error handling pattern extraction  
	â””â”€ **NEW**: API usage pattern extraction for external service detection  
â†“  
[chunk_fingerprint, Line 24, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py#L24)  
	â””â”€ Generates SHA-256 hash fingerprints for each chunk to eliminate duplicate embeddings  
â†“  
[chunker_factory.summarize_chunk, Line 176, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py#L176)  
	â””â”€ Creates concise summary keywords from chunks for retrieval relevance boosts  
â†“  
[build_code_relationship_map, Line 52, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py#L52)  
	â””â”€ Constructs mappings of code dependencies to understand file impact and relationships  
	â””â”€ **NEW**: Uses normalized paths for cross-platform compatibility  
â†“  
[HierarchicalIndexer.create_hierarchical_index, Line 21, core/hierarchical_indexer.py](https://github.com/anilbattini/codebase-qa/blob/main/core/hierarchical_indexer.py#L21)  
	â””â”€ Builds layered hierarchical indexes grouping chunks by modules, files, classes  
	â””â”€ **NEW**: Multi-level indices for component, file, business logic, UI flow, and API levels  
	â””â”€ **NEW**: Surfaces missing anchors/attributes for RAG pipeline health monitoring  
â†“  
(Sanitize chunks for embedding ingestion)  
	â””â”€ Cleans chunk contents and metadata ensuring compatibility with vector storage  
	â””â”€ **NEW**: Enhanced sanitization handles complex metadata structures  
â†“  
(Embed chunks in batches with OllamaEmbeddings via Ollama API)  
	â””â”€ Sends semantic chunks in batches to generate embeddings with consistent vector dimensions  
	â””â”€ **NEW**: Batch processing with progress tracking and timeout protection  
	â””â”€ **NEW**: Retry logic for embedding computation failures  
â†“  
(Store embedded vectors and metadata in persistent Chroma vector database)  
	â””â”€ **ENHANCED**: For incremental builds: updates existing database with new documents  
	â””â”€ **ENHANCED**: For full builds: creates new database from scratch  
	â””â”€ **NEW**: Handles incremental vs full database creation with proper error handling and fallbacks  
	â””â”€ **NEW**: Database lock prevention with connection cleanup  
â†“  
(Update git or file hash tracking records)  
	â””â”€ Records processed files for incremental rebuild detection on next run  
	â””â”€ **NEW**: Enhanced tracking with both Git commit and working directory changes  
â†“  
[ProcessManager.finish_rag_build, Line 33, core/process_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/process_manager.py#L33)  
	â””â”€ **NEW**: Marks RAG building as finished and clears build state  
	â””â”€ **NEW**: Re-enables all UI elements that were disabled during build  
	â””â”€ **NEW**: Cleans up process resources and logs build completion  
â†“  
[RagManager.build_rag_index completion, Line 206, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L206)  
	â””â”€ Finalizes by setting retriever and QA chain in session state for query answering  
	â””â”€ **NEW**: Uses provider-specific LLM configuration for QA chain setup  

---

**NO REBUILD REQUIRED (No changes detected):**  
â†“  
[App.py no changes handling, Line 89, core/app.py](https://github.com/anilbattini/codebase-qa/blob/main/core/app.py#L89)  
	â””â”€ **NEW**: Shows success message: "âœ… No file changes detected. RAG index is up to date."  
	â””â”€ **NEW**: Displays info box: "ðŸ’¡ No new files to process. The RAG index is already up to date with the latest changes."  
	â””â”€ **NEW**: Provides "ðŸ”„ Force Rebuild" button for manual rebuild option  
	â””â”€ **NEW**: Similar to project type change logic: asks user permission before major operations  
â†“  
[RagManager.load_existing_rag_index, Line 251, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L251)  
	â””â”€ Loads existing embeddings, vector DB, retriever, and QA chain from disk  
	â””â”€ **CRITICAL FIX**: Uses same embedding model as in build step to avoid dimension mismatches  
	â””â”€ **NEW**: Embedding model consistency check: `embedding_model = "nomic-embed-text:latest"`  
	â””â”€ **NEW**: Provider-specific LLM setup with fallback logic  
	â””â”€ Ensures session state is ready for query processing  
â†“  
RAG system is ready for queries with retriever and QA chain available in Streamlit session state  

---

**Debug Mode Activation (NEW SECTION):**  
If user wants to access debug tools  
â†“  
[UIComponents.render_welcome_screen â€“ 5-click debug, Line 288, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L288)  
	â””â”€ **NEW**: Tracks title button clicks (5 clicks to enable debug mode)  
	â””â”€ **NEW**: Shows debug click counter and enables debug mode after 5 clicks  
	â””â”€ **NEW**: Displays success message: "ðŸ”§ Debug mode enabled! Check the sidebar for debug options."  
â†“  
[UIComponents.render_debug_section, Line 388, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L388)  
	â””â”€ **NEW**: Renders comprehensive debug tools and inspection section  
	â””â”€ **NEW**: Creates tabs for Vector DB Inspector, Chunk Analyzer, Retrieval Tester, Build Status, Logs  
	â””â”€ **NEW**: Integrates with actual core functionality (not mock implementations)  

---

## ðŸŸ© User Query & Answer Flow

**Query Input and RAG Mode Check:**  
User enters a question in the chat UI input box  
â†“  
[UIComponents.render_chat_input, Line 347, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L347)  
	â””â”€ Captures user's natural language question input  
	â””â”€ Disables input if RAG system is not fully ready  
	â””â”€ **NEW**: Supports form-based input with proper submission handling  
â†“  
[App.py RAG disable check, Line 40, core/app.py](https://github.com/anilbattini/codebase-qa/blob/main/core/app.py#L40)  
	â””â”€ **NEW**: Checks "Disable RAG (query LLM directly)" toggle in sidebar  
	â””â”€ **NEW**: If RAG disabled: sends query directly to LLM without retrieval  
	â””â”€ **NEW**: If RAG enabled: proceeds with full RAG pipeline processing  
â†“  
[RagManager.is_ready, Line 328, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L328)  
	â””â”€ Checks session state to ensure retriever and QA chain objects are initialized  
	â””â”€ Prevents query submission if system isn't ready  
	â””â”€ **NEW**: Validates both retriever and provider-specific QA chain readiness  

---

**Enhanced Query Processing Pipeline:**  
â†“  
[ChatHandler.process_query, Line 43, core/chat_handler.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chat_handler.py#L43)  
	â””â”€ **NEW**: Enhanced query processing with Phase 3 context + full backward compatibility  
	â””â”€ **NEW**: Multi-phase processing: Intent â†’ Rewriting â†’ Retrieval â†’ Context â†’ Generation â†’ Ranking  
â†“  
[QueryIntentClassifier.classify_intent, Line 34, core/query_intent_classifier.py](https://github.com/anilbattini/codebase-qa/blob/main/core/query_intent_classifier.py#L34)  
	â””â”€ Applies pattern-based matching on user query to classify intent (overview, technical, business_logic, ui_flow, impact_analysis)  
	â””â”€ Returns intent label and confidence score to inform retrieval strategy  
	â””â”€ **NEW**: Enhanced intent classification with confidence scoring  
â†“  
[ChatHandler._rewrite_query_with_intent, Line 263, core/chat_handler.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chat_handler.py#L263)  
	â””â”€ **NEW**: Enhanced query rewriting with intent awareness  
	â””â”€ **NEW**: Uses centralized rewrite chain with project type and intent context  
	â””â”€ **NEW**: Includes fallback logic if rewriting fails  
â†“  
[RetrievalLogic.retrieve_with_fallback, Line 176, core/retrieval_logic.py](https://github.com/anilbattini/codebase-qa/blob/main/core/retrieval_logic.py#L176)  
	â””â”€ **NEW**: Multi-fallback retrieval strategy for robust document finding  
	â””â”€ **NEW**: Strategy 1: Try rewritten query first  
	â””â”€ **NEW**: Strategy 2: Fall back to original query if no results  
	â””â”€ **NEW**: Strategy 3: Extract key terms and search with those  
	â””â”€ **NEW**: Comprehensive logging of each retrieval attempt  
â†“  
[QueryIntentClassifier.get_query_context_hints, Line 64, core/query_intent_classifier.py](https://github.com/anilbattini/codebase-qa/blob/main/core/query_intent_classifier.py#L64)  
	â””â”€ Extracts relevant keywords or anchors based on classified intent  
	â””â”€ These hints boost relevant context retrieval and improve accuracy  
â†“  
[Retriever.invoke via session state, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py)  
	â””â”€ Performs vector similarity search in Chroma vector store  
	â””â”€ Retrieves top-k most semantically relevant code chunks for user query  
	â””â”€ **NEW**: Uses consistent embedding model to prevent dimension mismatches  

---

**Phase 3 Enhanced Context Assembly:**  
â†“  
[ContextBuilder.build_enhanced_context, Line 75, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L75)  
	â””â”€ **NEW**: Multi-strategy context assembly using cross-references  
	â””â”€ **NEW**: Supports both original hierarchical context and enhanced layered context  
	â””â”€ **NEW**: Selects appropriate context strategies based on query intent  
â†“  
[ContextBuilder._select_strategies, Line 197, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L197)  
	â””â”€ **NEW**: Selects context building strategies based on intent:  
		â””â”€ Overview: Hierarchical + Project Structure  
		â””â”€ Technical: Call Flow + Implementation Details  
		â””â”€ Business Logic: Inheritance + Validation Rules  
		â””â”€ Impact Analysis: Impact + Dependency Chains  
â†“  
[ContextBuilder._build_hierarchical_context, Line 222, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L222)  
	â””â”€ **NEW**: Builds hierarchical context layer using project structure  
â†“  
[ContextBuilder._build_call_flow_context, Line 242, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L242)  
	â””â”€ **NEW**: Builds call flow context layer using function relationships  
â†“  
[ContextBuilder._build_inheritance_context, Line 268, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L268)  
	â””â”€ **NEW**: Builds inheritance context layer using class hierarchies  
â†“  
[ContextBuilder._build_impact_context, Line 294, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L294)  
	â””â”€ **NEW**: Builds impact analysis context layer using dependency chains  
â†“  
[ContextBuilder._rank_context_layers, Line 332, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L332)  
	â””â”€ **NEW**: Ranks context layers by relevance to query intent  
â†“  
[ContextBuilder.format_context_for_llm, Line 355, core/context_builder.py](https://github.com/anilbattini/codebase-qa/blob/main/core/context_builder.py#L355)  
	â””â”€ **NEW**: Formats enhanced multi-layered context for LLM consumption  

---

**Enhanced Query Generation and Processing:**  
â†“  
[PromptRouter.build_enhanced_query, Line 47, core/prompt_router.py](https://github.com/anilbattini/codebase-qa/blob/main/core/prompt_router.py#L47)  
	â””â”€ **NEW**: Intent-driven prompt routing with specialized templates for RAG Codebase QA  
	â””â”€ **NEW**: Provider-adaptive templates (Ollama vs Cloud)  
	â””â”€ **NEW**: Original question preservation with enhanced context  
â†“  
[ChatHandler._analyze_impact_with_intent, Line 295, core/chat_handler.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chat_handler.py#L295)  
	â””â”€ **NEW**: Performs impact analysis if applicable to intent (impact_analysis queries)  
	â””â”€ **NEW**: Extracts file mentions and traces dependency chains  
â†“  
[RetrievalQA chain via provider-specific LLM, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py)  
	â””â”€ Constructs prompt consisting of user query plus retrieved code chunks with enhanced context  
	â””â”€ **NEW**: Uses ModelConfig.get_llm() factory for provider-agnostic LLM access  
		â””â”€ Sends prompt to configured LLM (Ollama or Cloud) for natural language generation  
â†“  
[ChatHandler._rerank_docs_by_intent, Line 230, core/chat_handler.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chat_handler.py#L230)  
	â””â”€ **NEW**: Document re-ranking based on intent and relevance scoring  
	â””â”€ **NEW**: Intent-aware scoring that prioritizes relevant document types  
	â””â”€ **NEW**: Returns actual Document objects (not just file name strings)  
â†“  
[build_rag.get_impact, Line 589, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py#L589)  
	â””â”€ Performs impact analysis tracing file dependencies for related/affected code  
	â””â”€ Returns list of impacted files to augment response metadata  
	â””â”€ **NEW**: Uses normalized path handling for cross-platform compatibility  

---

**Answer Validation & Pipeline Diagnostics (NEW SECTION):**  
â†“  
[AnswerValidationHandler.validate_answer_quality, Line 33, core/answer_validation_handler.py](https://github.com/anilbattini/codebase-qa/blob/main/core/answer_validation_handler.py#L33)  
	â””â”€ **NEW**: Enhanced local validation building on existing quality analysis  
	â””â”€ **NEW**: Multi-metric scoring (relevancy, completeness, accuracy, code-specific quality)  
	â””â”€ **NEW**: Overall score calculation with weighted components  
â†“  
[AnswerValidationHandler.diagnose_quality_issue, Line 118, core/answer_validation_handler.py](https://github.com/anilbattini/codebase-qa/blob/main/core/answer_validation_handler.py#L118)  
	â””â”€ **NEW**: Comprehensive pipeline diagnostics to identify quality bottlenecks  
	â””â”€ **NEW**: Analyzes rewriting quality, retrieval coverage, and answer quality  
	â””â”€ **NEW**: Generates actionable fix recommendations with priority levels  
â†“  
[UIComponents.render_chat_history, Line 359, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L359)  
	â””â”€ Renders generated answer, source chunk attributions, and impact metadata in UI  
	â””â”€ Supports expansion, chat context, and debug information display  
	â””â”€ **NEW**: Enhanced metadata display with intent, confidence, rewritten query  
	â””â”€ **NEW**: Handles both old (4 items) and new (5 items) chat history formats for backward compatibility  
	â””â”€ **NEW**: Shows top 5 sources with detailed metadata and chunk information  

---

**Debug Tools Integration (When Debug Mode Enabled):**  
â†“  
[UIComponents.render_debug_section, Line 388, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L388)  
	â””â”€ **NEW**: Shows comprehensive debug tools in expandable section  
	â””â”€ **NEW**: Vector DB Inspector: Database statistics and health checking  
	â””â”€ **NEW**: Chunk Analyzer: File-specific chunk analysis with metadata  
	â””â”€ **NEW**: Retrieval Tester: Query performance testing with relevance scores  
	â””â”€ **NEW**: Build Status: Database file analysis and tracking status  
	â””â”€ **NEW**: Logs Viewer: Real-time log file access with download capability  
	â””â”€ **NEW**: All tools use existing session state retriever (no recreation)  

---

**Processing Logs and Monitoring:**  
â†“  
[UIComponents.render_processing_logs, Line 646, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L646)  
	â””â”€ **NEW**: Renders processing logs section with scrollable display  
	â””â”€ **NEW**: Shows last 50 logs to prevent overwhelming display  
	â””â”€ **NEW**: Provides clear and copy actions for log management  
	â””â”€ **NEW**: Only visible when debug mode is enabled

---

## ðŸŸ¨ Enhanced Provider Selection Flow

**Provider Configuration:**  
User opens application and needs to configure LLM provider  
â†“  
[UIComponents.render_sidebar_config, Line 72, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L72)  
	â””â”€ Shows provider selection dropdown: "Choose Provider...", "Ollama (Local)", "Cloud (OpenAI Compatible)"  
â†“  
**If Ollama Selected:**  
[ModelConfig.set_provider("ollama"), Line 214, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L214)  
	â””â”€ Sets provider to "ollama" in centralized configuration  
	â””â”€ Shows locked/disabled model and endpoint fields for consistency  
	â””â”€ Uses default values: model="llama3.1:latest", endpoint="http://localhost:11434"  
â†“  
**If Cloud Selected:**  
[ModelConfig.set_provider("cloud"), Line 214, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L214)  
	â””â”€ Sets provider to "cloud" in centralized configuration  
	â””â”€ Shows endpoint options: "From Environment" or "Custom Endpoint"  
	â””â”€ Validates CLOUD_API_KEY environment variable  
	â””â”€ Uses hardcoded model: "gpt-4.1"  
	â””â”€ Still requires local Ollama for embeddings (editable settings)  
â†“  
[ModelConfig.get_llm, Line 70, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L70)  
	â””â”€ Factory method returns appropriate LLM client:  
		â””â”€ For Ollama: ChatOllama instance  
		â””â”€ For Cloud: CustomLLMClient instance with Runnable compatibility  
â†“  
[CustomLLMClient.invoke_with_system_user, Line 59, core/custom_llm_client.py](https://github.com/anilbattini/codebase-qa/blob/main/core/custom_llm_client.py#L59)  
	â””â”€ **NEW**: Direct method for system/user prompt separation  
	â””â”€ **NEW**: Handles OpenAI-compatible API calls with proper message formatting  
	â””â”€ **NEW**: Called directly from query.chat_handler.py for cloud provider queries  

---

## ðŸŸª Process Management & UI Protection Flow

**Build Process Protection:**  
When RAG building starts, protect the process from UI interference  
â†“  
[ProcessManager.start_rag_build, Line 18, core/process_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/process_manager.py#L18)  
	â””â”€ Records build start time and process ID for timeout detection  
	â””â”€ Sets building flag in session state to prevent concurrent operations  
	â””â”€ Logs build start with project details  
â†“  
[ProcessManager.disable_ui_during_build, Line 70, core/process_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/process_manager.py#L70)  
	â””â”€ Returns safe UI state during build to prevent user interference  
	â””â”€ Blocks force rebuild, debug mode, and project type changes  
	â””â”€ Shows build status with progress information  
â†“  
[ProcessManager.check_rag_build_timeout, Line 50, core/process_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/process_manager.py#L50)  
	â””â”€ Monitors build timeout (15 minutes) and provides recovery options  
	â””â”€ Shows timeout warning and force stop option if exceeded  
â†“  
[ProcessManager.finish_rag_build, Line 33, core/process_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/process_manager.py#L33)  
	â””â”€ Clears building flag and re-enables all UI elements  
	â””â”€ Cleans up process resources and logs completion  

---

This comprehensive update ensures all recent improvements and architectural changes from 2025-09-03 are accurately represented with proper GitHub links, exact line numbers, and detailed flow descriptions for all major user interactions and internal processing pipelines.
