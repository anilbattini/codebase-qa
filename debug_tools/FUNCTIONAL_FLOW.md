# FUNCTIONAL FLOW DIRAGRAM

## ðŸŸ¦ RAG Index Build & Ready Flow

```python
Sidebar: user selects project directory, project type, model, and endpoint       [BLUE]
|  (User input in the sidebar UI initializes project setup parameters)
v
[UIComponents.render_sidebar_config, Line no: 19, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L19)
    â€” Renders sidebar inputs for project directory, project type, Ollama model and endpoint.
    â€” Handles user changes, validations, and warnings about existing data.

|
v
[RagManager.initialize_session_state, Line no: 14, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L14)
    â€” Initializes critical Streamlit session state keys like retriever and QA chain for stable app state.
    â€” Ensures consistent session during build or load operations.

|
v
[ProjectConfig.__init__, Line no: 112, core/config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/config.py#L112)
    â€” Detects or applies project type (auto/manual).
    â€” Loads language specific file extensions, chunking rules, ignore patterns, and project indicators.

|
v
[RagManager.should_rebuild_index, Line no: 74, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L74)
    â€” Checks presence of vector DB SQLite file, git/hash tracking files.
    â€” Detects if source files have changed or if force rebuild is requested.

|--- If REBUILD is needed (new or changed files, or force rebuild)
|    |
|    v
|    [RagManager.cleanup_existing_files, Line no: 41, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L41)
|        â€” Deletes existing vector DB directories and clears session state to ensure clean rebuild.
|        â€” Handles retry logic to overcome file locks during cleanup.

|    |
|    v
|    [RagManager.build_rag_index, Line no: 165, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L165)
|        â€” Coordinates full RAG build workflow: files scanning, chunking, embedding, indexing.
|        â€” Sets retriever and QA chain objects into Streamlit session state when done.

|    |
|    v
|    [build_rag, Line no: 19, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py#L19)
|        â€” Reads files, applies chunking per language, extracts semantic metadata.
|        â€” Creates output folders and handles incremental file processing via git/hash tracking.
|        â€” Initializes embedding model and verifies Ollama endpoint responsiveness.
|        â€” Processes each source file: chunks files, extracts metadata, deduplicates using chunk fingerprints.
|        â€” Builds code relationships and hierarchical index files.
|        â€” Sanitizes chunks and sends batches for embedding via Ollama API.
|        â€” Persists embeddings in Chroma vector database.
|        â€” Updates file tracking and logs detailed stats on the process.

|    |
|    v
|    [ProjectConfig.create_directories, Line no: 181, core/config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/config.py#L181)
|        â€” Ensures all database and logs directories exist for current project type.

|    |
|    v
|    [FileHashTracker.get_changed_files, core/git_hash_tracker.py](https://github.com/anilbattini/codebase-qa/blob/main/core/git_hash_tracker.py)
|        â€” Obtains list of newly changed or added files for incremental processing.

|    |
|    v
|    [ModelConfig.get_embedding_model, Line no: 63, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L63)
|        â€” Retrieves the embedding model name to ensure consistency in embedding dimensions.

|    |
|    v
|    [ModelConfig.get_ollama_endpoint, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py)
|        â€” Retrieves the Ollama server endpoint URL used for embedding and LLM calls.

|    |
|    v
|    [chunker_factory.get_chunker, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py)
|        â€” Selects language-specific chunking strategy function per file extension.

|    |
|    v
|    [chunker_factory.chunker, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py)
|        â€” Executes semantic chunking, splitting code into meaningful segments for embedding.

|    |
|    v
|    [MetadataExtractor.create_enhanced_metadata, core/metadata_extractor.py](https://github.com/anilbattini/codebase-qa/blob/main/core/metadata_extractor.py)
|        â€” Extracts detailed chunk meta class names, function names, dependencies, semantic anchors.

|    |
|    v
|    [chunk_fingerprint, Line no: 13, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py#L13)
|        â€” Generates SHA-256 hash fingerprints for each chunk to eliminate duplicate embeddings.

|    |
|    v
|    [chunker_factory.summarize_chunk, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py)
|        â€” Creates concise summary keywords from chunks for retrieval relevance boosts.

|    |
|    v
|    [build_code_relationship_map, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py)
|        â€” Constructs mappings of code dependencies to understand file impact and relationships.

|    |
|    v
|    [HierarchicalIndexer.create_hierarchical_index, core/hierarchical_indexer.py](https://github.com/anilbattini/codebase-qa/blob/main/core/hierarchical_indexer.py)
|        â€” Builds layered hierarchical indexes grouping chunks by modules, files, classes.

|    |
|    v
|    (Sanitize chunks for embedding ingestion)
|        â€” Cleans chunk contents and metadata ensuring compatibility with vector storage.

|    |
|    v
|    (Embed chunks in batches with OllamaEmbeddings via Ollama API)
|        â€” Sends semantic chunks in batches to generate embeddings with consistent vector dimensions.

|    |
|    v
|    (Store embedded vectors and metadata in persistent Chroma vector database)
|        â€” Writes the computed embeddings along with metadata for similarity search on queries.

|    |
|    v
|    (Update git or file hash tracking records)
|        â€” Records processed files for incremental rebuild detection on next run.

|    |
|    v
|    [RagManager.build_rag_index, Line no: 165, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L165)
|        â€” Finalizes by setting retriever and QA chain in session state for query answering.

|--- If NO rebuild required (No changes detected)
    |
    v
    [RagManager.load_existing_rag_index, Line no: 194, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L194)
    â€” Loads existing embeddings, vector DB, retriever, and QA chain from disk.
    â€” Uses same embedding model as in build step to avoid dimension mismatches.
    â€” Ensures session state is ready for query processing.

|
v
RAG system is ready for queries with retriever and QA chain available in Streamlit session state.


```

## ðŸŸ© User Query & Answer Flow

```python
User enters a question in the chat UI input box            [GREEN]
|
v
[UIComponents.render_chat_input, Line no: 161, core/ui_components.py](https://github.com/kumarb/codebase-qa/blob/main/core/ui_components.py#L161)
    â€” Captures userâ€™s natural language question input.
    â€” Disables input if RAG system is not fully ready.

|
v
[RagManager.is_ready, Line no: 195, core/rag_manager.py](https://github.com/kumarb/codebase-qa/blob/main/core/rag_manager.py#L195)
    â€” Checks session state to ensure retriever and QA chain objects are initialized.
    â€” Prevents query submission if system isnâ€™t ready.

|
v
[QueryIntentClassifier.classify_intent, Line no: 29, core/query_intent_classifier.py](https://github.com/kumarb/codebase-qa/blob/main/core/query_intent_classifier.py#L29)
    â€” Applies pattern-based matching on user query to classify intent (e.g., overview, validation).
    â€” Returns intent label and confidence score to inform retrieval strategy.

|
v
[QueryIntentClassifier.get_query_context_hints, Line no: 56, core/query_intent_classifier.py](https://github.com/kumarb/codebase-qa/blob/main/core/query_intent_classifier.py#L56)
    â€” Optionally extracts relevant keywords or anchors based on classified intent.
    â€” These hints boost relevant context retrieval.

|
v
[Retriever.get_relevant_documents, core/rag_manager.py]
    â€” Performs vector similarity search in Chroma vector store.
    â€” Retrieves top-k most semantically relevant code chunks for user query.

|
v
[ChatHandler & RetrievalQA (combined with LangChain library), core/chat_handler.py](https://github.com/kumarb/codebase-qa/blob/main/core/chat_handler.py)
    â€” Constructs prompt consisting of user query plus retrieved code chunks with metadata.
    â€” Sends prompt to Ollama LLM for natural language generation of the answer.

|
v
[build_rag.get_impact, Line no: 379, core/build_rag.py](https://github.com/kumarb/codebase-qa/blob/main/core/build_rag.py#L379)
    â€” Optionally performs impact analysis tracing file dependencies for related/affected code.
    â€” Returns list of impacted files to augment response metadata.

|
v
[UIComponents.render_chat_history, Line no: 282, core/ui_components.py](https://github.com/kumarb/codebase-qa/blob/main/core/ui_components.py#L282)
    â€” Renders generated answer, source chunk attributions, and impact metadata in UI.
    â€” Supports expansion, chat context, and debug information display.

```

