# FUNCTIONAL FLOW DIAGRAM

## ðŸŸ¦ RAG Index Build & Ready Flow

Sidebar: user selects project directory, project type, model, and endpoint       
â†“  
[UIComponents.render_sidebar_config, Line no: 19, core/ui_components.py](https://github.com/anilbattini/codebase-qa/blob/main/core/ui_components.py#L19)  
  â””â”€ Renders sidebar inputs for project directory, project type, Ollama model and endpoint.  
  â””â”€ Handles user changes, validations, and warnings about existing data.  
â†“  
[RagManager.initialize_session_state, Line no: 14, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L14)  
  â””â”€ Initializes critical Streamlit session state keys like retriever and QA chain for stable app state.  
  â””â”€ Ensures consistent session during build or load operations.  
â†“  
[ProjectConfig.__init__, Line no: 112, core/config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/config.py#L112)  
  â””â”€ Detects or applies project type (auto/manual).  
  â””â”€ Loads language specific file extensions, chunking rules, ignore patterns, and project indicators.  
â†“  
[RagManager.should_rebuild_index, Line no: 74, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L74)  
  â””â”€ Checks presence of vector DB SQLite file, git/hash tracking files.  
  â””â”€ Detects if source files have changed or if force rebuild is requested.  

If REBUILD is needed (new or changed files, or force rebuild)  
â†“  
[RagManager.cleanup_existing_files, Line no: 41, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L41)  
  â””â”€ Deletes existing vector DB directories and clears session state to ensure clean rebuild.  
  â””â”€ Handles retry logic to overcome file locks during cleanup.  
â†“  
[RagManager.build_rag_index, Line no: 165, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L165)  
  â””â”€ Coordinates full RAG build workflow: files scanning, chunking, embedding, indexing.  
  â””â”€ Sets retriever and QA chain objects into Streamlit session state when done.  
â†“  
[build_rag, Line no: 19, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py#L19)  
  â””â”€ Reads files, applies chunking per language, extracts semantic metadata.  
  â””â”€ Creates output folders and handles incremental file processing via git/hash tracking.  
  â””â”€ Initializes embedding model and verifies Ollama endpoint responsiveness.  
  â””â”€ Processes each source file: chunks files, extracts metadata, deduplicates using chunk fingerprints.  
  â””â”€ Builds code relationships and hierarchical index files.  
  â””â”€ Sanitizes chunks and sends batches for embedding via Ollama API.  
  â””â”€ Persists embeddings in Chroma vector database.  
  â””â”€ Updates file tracking and logs detailed stats on the process.  
â†“  
[ProjectConfig.create_directories, Line no: 181, core/config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/config.py#L181)  
  â””â”€ Ensures all database and logs directories exist for current project type.  
â†“  
[FileHashTracker.get_changed_files, core/git_hash_tracker.py](https://github.com/anilbattini/codebase-qa/blob/main/core/git_hash_tracker.py)  
  â””â”€ Obtains list of newly changed or added files for incremental processing.  
â†“  
[ModelConfig.get_embedding_model, Line no: 63, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py#L63)  
  â””â”€ Retrieves the embedding model name to ensure consistency in embedding dimensions.  
â†“  
[ModelConfig.get_ollama_endpoint, core/model_config.py](https://github.com/anilbattini/codebase-qa/blob/main/core/model_config.py)  
  â””â”€ Retrieves the Ollama server endpoint URL used for embedding and LLM calls.  
â†“  
[chunker_factory.get_chunker, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py)  
  â””â”€ Selects language-specific chunking strategy function per file extension.  
â†“  
[chunker_factory.chunker, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py)  
  â””â”€ Executes semantic chunking, splitting code into meaningful segments for embedding.  
â†“  
[MetadataExtractor.create_enhanced_metadata, core/metadata_extractor.py](https://github.com/anilbattini/codebase-qa/blob/main/core/metadata_extractor.py)  
  â””â”€ Extracts detailed chunk meta class names, function names, dependencies, semantic anchors.  
â†“  
[chunk_fingerprint, Line no: 13, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py#L13)  
  â””â”€ Generates SHA-256 hash fingerprints for each chunk to eliminate duplicate embeddings.  
â†“  
[chunker_factory.summarize_chunk, core/chunker_factory.py](https://github.com/anilbattini/codebase-qa/blob/main/core/chunker_factory.py)  
  â””â”€ Creates concise summary keywords from chunks for retrieval relevance boosts.  
â†“  
[build_code_relationship_map, core/build_rag.py](https://github.com/anilbattini/codebase-qa/blob/main/core/build_rag.py)  
  â””â”€ Constructs mappings of code dependencies to understand file impact and relationships.  
â†“  
[HierarchicalIndexer.create_hierarchical_index, core/hierarchical_indexer.py](https://github.com/anilbattini/codebase-qa/blob/main/core/hierarchical_indexer.py)  
  â””â”€ Builds layered hierarchical indexes grouping chunks by modules, files, classes.  
â†“  
(Sanitize chunks for embedding ingestion)  
  â””â”€ Cleans chunk contents and metadata ensuring compatibility with vector storage.  
â†“  
(Embed chunks in batches with OllamaEmbeddings via Ollama API)  
  â””â”€ Sends semantic chunks in batches to generate embeddings with consistent vector dimensions.  
â†“  
(Store embedded vectors and metadata in persistent Chroma vector database)  
  â””â”€ Writes the computed embeddings along with metadata for similarity search on queries.  
â†“  
(Update git or file hash tracking records)  
  â””â”€ Records processed files for incremental rebuild detection on next run.  
â†“  
[RagManager.build_rag_index, Line no: 165, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L165)  
  â””â”€ Finalizes by setting retriever and QA chain in session state for query answering.  

If NO rebuild required (No changes detected)  
â†“  
[RagManager.load_existing_rag_index, Line no: 194, core/rag_manager.py](https://github.com/anilbattini/codebase-qa/blob/main/core/rag_manager.py#L194)  
  â””â”€ Loads existing embeddings, vector DB, retriever, and QA chain from disk.  
  â””â”€ Uses same embedding model as in build step to avoid dimension mismatches.  
  â””â”€ Ensures session state is ready for query processing.  
â†“  
RAG system is ready for queries with retriever and QA chain available in Streamlit session state.


## ðŸŸ© User Query & Answer Flow

User enters a question in the chat UI input box           
â†“  
[UIComponents.render_chat_input, Line no: 161, core/ui_components.py](https://github.com/kumarb/codebase-qa/blob/main/core/ui_components.py#L161)  
  â””â”€ Captures userâ€™s natural language question input.  
  â””â”€ Disables input if RAG system is not fully ready.  
â†“  
[RagManager.is_ready, Line no: 195, core/rag_manager.py](https://github.com/kumarb/codebase-qa/blob/main/core/rag_manager.py#L195)  
  â””â”€ Checks session state to ensure retriever and QA chain objects are initialized.  
  â””â”€ Prevents query submission if system isnâ€™t ready.  
â†“  
[QueryIntentClassifier.classify_intent, Line no: 29, core/query_intent_classifier.py](https://github.com/kumarb/codebase-qa/blob/main/core/query_intent_classifier.py#L29)  
  â””â”€ Applies pattern-based matching on user query to classify intent (e.g., overview, validation).  
  â””â”€ Returns intent label and confidence score to inform retrieval strategy.  
â†“  
[QueryIntentClassifier.get_query_context_hints, Line no: 56, core/query_intent_classifier.py](https://github.com/kumarb/codebase-qa/blob/main/core/query_intent_classifier.py#L56)  
  â””â”€ Optionally extracts relevant keywords or anchors based on classified intent.  
  â””â”€ These hints boost relevant context retrieval.  
â†“  
[Retriever.get_relevant_documents, core/rag_manager.py](https://github.com/kumarb/codebase-qa/blob/main/core/rag_manager.py)  
  â””â”€ Performs vector similarity search in Chroma vector store.  
  â””â”€ Retrieves top-k most semantically relevant code chunks for user query.  
â†“  
[ChatHandler & RetrievalQA (combined with LangChain library), core/chat_handler.py](https://github.com/kumarb/codebase-qa/blob/main/core/chat_handler.py)  
  â””â”€ Constructs prompt consisting of user query plus retrieved code chunks with metadata.  
  â””â”€ Sends prompt to Ollama LLM for natural language generation of the answer.  
â†“  
[build_rag.get_impact, Line no: 379, core/build_rag.py](https://github.com/kumarb/codebase-qa/blob/main/core/build_rag.py#L379)  
  â””â”€ Optionally performs impact analysis tracing file dependencies for related/affected code.  
  â””â”€ Returns list of impacted files to augment response metadata.  
â†“  
[UIComponents.render_chat_history, Line no: 282, core/ui_components.py](https://github.com/kumarb/codebase-qa/blob/main/core/ui_components.py#L282)  
  â””â”€ Renders generated answer, source chunk attributions, and impact metadata in UI.  
  â””â”€ Supports expansion, chat context, and debug information display.
